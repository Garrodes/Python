{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373d0985-a810-411e-a78a-8a635bc3fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c50e3-88d5-41f7-a6fd-d511d0be50f9",
   "metadata": {},
   "source": [
    "# 1. Fonctions pour affiner les modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce5b1a-6e4e-41fb-a85a-f455c6b3c1c6",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de répertorier différentes fonctions qui vont permettre d'ajuster les paramètres de modèles pour avoir la MAE la plus minime possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddb3adc-7efc-4730-9a31-1b92308d41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf0098-aa38-460a-be78-273ae887f9db",
   "metadata": {},
   "source": [
    "## RandomForest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7137064-6894-4d0d-b6c6-9dc3d74acd8d",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37200ec-9390-4c8b-bf12-8b5851ca705a",
   "metadata": {},
   "source": [
    "Parametrage des n_estimators avec un cv donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528548e-ad96-45d5-b7e2-0dd05b6b9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_RF(n_estimators, cv):\n",
    "    \"\"\"Return the average MAE of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    cv --- number of validation\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline(steps=[('imputer',SimpleImputer()),('model',RandomForestRegressor(n_estimators = n_estimators, random_state=0))])\n",
    "    scores = -1 * cross_val_score(pipeline, X, y,\n",
    "                              cv=cv,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6c3da-c157-4e89-8fd0-513da2c5df51",
   "metadata": {},
   "source": [
    "### Classique MAE pour RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37c499e-d17a-4bb0-81fc-6a216d7b97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model= RandomForestRegressor(n_estimators=100, reandom_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97b033-d2cc-45a3-a17a-c72b789d2a9c",
   "metadata": {},
   "source": [
    "## XG-Boost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6859f777-f4c8-4788-abd3-cdf869d16709",
   "metadata": {},
   "source": [
    "Parametrage des n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae296f68-5601-4c6e-8c16-b4c126525cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_XGBoost(n_estimator):\n",
    "    model = XGBRegressor(n_estimators=n_estimator, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(preds, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd166aa-eaf7-4941-8041-a56e387465c4",
   "metadata": {},
   "source": [
    "Parametrage du learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13aa1c7-3061-4ce0-946d-d06059a4dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_XGB_lr(learning_rate):\n",
    "    model = XGBRegressor(n_estimators = 1000, learning_rate= learning_rate, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(preds, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b19b75-3cc4-4269-a94f-44aab279dcb2",
   "metadata": {},
   "source": [
    "# 2 Fonctions de featuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a34bbe-7b73-4704-b69a-1b0d3747dd3d",
   "metadata": {},
   "source": [
    "## 2.1 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9700d3-58e6-4fba-af9b-66c192f7110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4188c30-60d1-4932-83ec-7761297d6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f1b8bc-0d15-474b-b41a-1df4c11b47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665dd147-cb7e-4b3d-8d08-b34ebb94898d",
   "metadata": {},
   "source": [
    "# 3 Fonctions de preprocess "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940a7a8-7c3d-4c4f-8718-72bc60377c84",
   "metadata": {},
   "source": [
    "# 3.1 Categorical Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef554d71-53d0-45ec-895b-0229ff9fb6bc",
   "metadata": {},
   "source": [
    "Fonction qui pour un set de données d'entrainement donné retourne les colonnnes catégoricielles avec leur cardinal si définit comme Vrai( pour vraiment être flemmard ) sinon renvoi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356b873f-0975-4d65-82b3-d145629c2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_cols(X_train, card=False):\n",
    "        return [col for col in X_train.columns if X_train.col.dtype == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08611d6a-2be0-4790-a6f5-c6444de21409",
   "metadata": {},
   "source": [
    "Fonction qui pour une liste de colonnes \"catégoricielles\"  et un cardinal minimum donné , retourne les colonnes à One Hot ou à Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88378bdd-30b0-40fc-adbb-142f277f0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_cols_strategy(obj_cols, card):\n",
    "    ordinal_cols = []\n",
    "    one_hot_cols = []\n",
    "    for col in obj_cols:\n",
    "        col_card = X_train.col.nunique()\n",
    "        if col_card >= card:\n",
    "            ordinal_cols.append(col)\n",
    "        else:\n",
    "            one_hot_cols.append(col)\n",
    "    return ordinal_cols, one_hot_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e9697-f198-4dd3-9d44-9e93fb0abf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pour les colonnes à OH , retourne un X_train , X_valid qui ont été One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0428ec-6b61-4e2e-ae5f-e9232dc29fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_one_hot_encode(low_cardinality_cols):\n",
    "    # Apply one-hot encoder to each column with categorical data\n",
    "    # On pourra modifier le handle_unknown ou différents paramètres de OneHotEncoder\n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "    OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = X_train.index\n",
    "    OH_cols_valid.index = X_valid.index\n",
    "\n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    num_X_train = X_train.drop(object_cols, axis=1)\n",
    "    num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "    OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "    # Ensure all columns have string type\n",
    "    OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "    OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "    return OH_X_train, OH_X_valid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86483e55-3d90-4583-a367-9153e90e316f",
   "metadata": {},
   "source": [
    "Meme principe pour un ordinal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcde3ed-7d05-4102-a756-1b3af79b9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_ord_encode(high_cardinality_cols):\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    ord_X_train[high_cardinality_cols]=ordinal_encoder.fit_transform(X_train[high_cardinality_cols])\n",
    "    ord_X_valid[high_cardinality_cols]=ordinal_encoder.transform(X_train[high_cardinality_cols])\n",
    "    return ord_X_train, ord_X_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a0378-b92a-436b-a6e4-80b61b425e17",
   "metadata": {},
   "source": [
    "Si des catégories sont présentes sur le set de validation mais pas sur celui d'entrainement, <br>\n",
    "En les \"encodant\" on peut avoir des soucis .... <br>\n",
    "La fonction suivante permet de drop celles-ci si c'est la stratégie adoptée pour les gérer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17a9a9-ccfe-4a67-8927-0b90d94ee750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_categ_cols_withpb(obj_cols):\n",
    "    # Columns that can be safely ordinal encoded\n",
    "    good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]      \n",
    "    # Problematic columns that will be dropped from the dataset\n",
    "    bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "    \n",
    "    label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "    label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "    return label_X_train, label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04617e2-dde2-425a-8e39-672f18adeda6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
